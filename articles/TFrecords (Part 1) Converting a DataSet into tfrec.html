<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>TFrecords (Part 1): Converting a DataSet into tfrecordÂ files</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-interactiveBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}

.back-to-home {
    position: absolute;
    top: 20px;
    left: 20px;
    z-index: 1;
}

.back-to-home a {
    text-decoration: none;
    color: #fff;
    font-weight: bold;
    background-color: rgba(0, 0, 0, 0.7);
    padding: 6px 10px;
    border-radius: 4px;
}
	
</style></head><body><article id="d3d55dde-3c4a-4484-a2dc-ead25d989033" class="page sans">
	<header>
		<div class="back-to-home">
			<a href="/">Back to Home</a>
		</div>
		<img class="page-cover-image" src="https://www.notion.so/images/page-cover/woodcuts_7.jpg" style="object-position:center 70%"/><div class="page-header-icon page-header-icon-with-cover"><span class="icon">ð¯</span></div><h1 class="page-title"><strong>TFrecords (Part 1): Converting a DataSet into tfrecordÂ files</strong></h1><p class="page-description"></p><table class="properties"><tbody></tbody></table></header><div class="page-body"><p id="9c4e1c4f-1be7-4ce7-8f69-c24b1265b772" class="">When taking ML/Deep Learning Courses, it is common to have access to pre-loaded datasets like MNIST, FashionMNIST etc. as they come with Deep Learning frameworks like Tensorflow. But in real-world applications, your dataset would most likely not be readily available like this. Also, It might be too large to fit into memory at once.</p><p id="f474b749-e3b7-4067-9993-2f43e7c6e72b" class="">TFrecords offer a unique solution to the problem of training models with large datasets. A tensorflow record (tfrecord) is a binary file format designed to be efficient for storing and loading large datasets. They make training an ML model easy and work well with different Deep Learning and Machine Learning libraries.</p><h2 id="cc867603-5c7f-4065-bb82-5732da46f21c" class="">HOW?</h2><p id="5c013fdf-a5ad-452f-8f4a-a58ea5d85efd" class="">Here, Iâd be showing how to use tfrecords. First, you have to convert your dataset into tfrecords, how to read a tfrecord file and finally, how to train a Machine Learning Model using tfrecords.</p><p id="46f55588-f6da-4c93-8ce0-db114c3783da" class="">In this part, I would be focusing solely on converting your dataset into tfrecords.</p><p id="748bd41f-2dd2-4e3e-9f3d-413b67ae1612" class="">For this, Iâd be using the<strong>Â </strong><a href="https://www.kaggle.com/competitions/rsna-breast-cancer-detection">RSNA Screening Mammography Breast Cancer Detection</a>Â dataset. It contains over 50,000 medical images and is over 300GB in size, so itâs perfect for this. It also has aÂ <code>train.csv</code>Â file that contains other useful information about the images and the target.</p><p id="3d96694f-7ee1-4456-9905-ab45ca3ac67e" class="">The first step is usually to load your dataset into a juypter notebook session or your local computer. Iâm using a Kaggle Notebook, so this is fairly straightforward.</p><p id="55f17d20-e1af-471d-8d1c-18c73c2ddce8" class="">Hereâs a snapshot of the dataset and the first two columns of theÂ <code>train.csv</code>Â file.</p><figure id="2e954978-9ace-4eba-b537-068b21a4cc6d" class="image"><a href="https://cdn-images-1.medium.com/max/800/1*yxjYpNPmS96m-vdBi3cgzg.png"><img style="width:288px" src="https://cdn-images-1.medium.com/max/800/1*yxjYpNPmS96m-vdBi3cgzg.png"/></a><figcaption>Each folder contains images from aÂ patient.</figcaption></figure><figure id="e71092c2-e440-4198-86a7-e925a5ec59c9" class="image"><a href="https://cdn-images-1.medium.com/max/800/1*3IS0tqLLzZCP6kLPEMm8YQ.png"><img src="https://cdn-images-1.medium.com/max/800/1*3IS0tqLLzZCP6kLPEMm8YQ.png"/></a><figcaption>Each row contains additional information about theÂ patient.</figcaption></figure><p id="adecb908-8971-43f8-b12c-eeb9352f520d" class="">The focus here would be to have the image and its corresponding target value as a record/example in the tfrecord file.</p><p id="8bddd7cd-7c33-406b-8915-991c905764f4" class="">The first step is to specify the number of records we want in each tfrecord file. Usually, the number of records depends on your dataset. Iâd be using 1000 records here.</p><pre id="1acc6f68-4262-4da6-8f30-d43cf7cb679e" class="code"><code>NUM_RECORDS = 1000</code></pre><p id="f6a57f83-bd9c-41c7-b374-b15f326cefa5" class="">Next, based on the number of records, we figure out how many tfrecord files we would need to store the entire dataset.</p><pre id="0de59532-6562-459d-8f24-cebbcdb8c32d" class="code"><code>num_tfrecords = max(train.shape) // NUM_RECORDS

if max(train.shape) % NUM_RECORDS:
	num_tfrecords += 1  #add one record if there are any remaining samples</code></pre><p id="789a62eb-d1c1-42df-b4d6-a3169a4e91cf" class="">Then we define some helper functions.</p><p id="3b3e0ffa-a08c-4390-b825-b09393d976bf" class="">To use tfrecords, we have to define helper functions that would help turn the data into aÂ <code>tf.train.Feature</code>Â object which would later be used as a feature in theÂ <code>tf.train.Example</code>Â protocol buffer. Here we will need different helper functions to handle the different data types in our dataset. Since there are two datatypes in the dataset,Â <code>np.ndarray</code>Â andÂ <code>int64</code>Â , two helper functions are defined.</p><p id="52d4aa70-c435-4264-a27d-b56e8bfda111" class="">Here are the helper functions:</p><pre id="1ed4aa63-ccc5-4c77-b056-203b4836f3f3" class="code"><code>def image_feature(value):
    &quot;&quot;&quot;Returns a bytes_list from a string / byte.&quot;&quot;&quot;
    return tf.train.Feature(
        bytes_list=tf.train.BytesList(value=[tf.io.encode_png(value).numpy()])
    )

def int64_feature(value):
    &quot;&quot;&quot;Returns an int64_list from a bool / enum / int / uint.&quot;&quot;&quot;
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))</code></pre><p id="fd387bb6-ac6c-482b-aa49-104daf929d53" class=""><code>tf.io.encode_png</code>Â converts and compresses tensors to png.Â <code>tf.io</code>Â also contains aÂ <code>encode_jpg</code>Â function to convert tensors to jpg.</p><p id="abf39be1-f60f-4c30-bb7f-305e9f7b1864" class="">Here, I show an additional step for processing the images from Dicom files. Dicom (`.dcm`) files are used for storing medical images and also contain information about the patients. To readÂ <code>.dcm</code>Â files in Python, use theÂ <code>pydicom</code>Â library. Hereâs an example</p><pre id="5d5ef844-5fd3-4261-95dc-8a8bd7401be1" class="code code-wrap"><code>import pydicom as dicom

dcm_path = &#x27;.../10006/1459541791.dcm&#x27;
ds = dicom.dcm_read(dcm_path) #read dcm file from directory
image = ds.pixel_array #get image</code></pre><p id="16235180-d98a-4cee-b572-6d052db7fb57" class="">With this information, we create a preprocessing function that reads the dcm file from path and converts it to aÂ <code>(224, 224, 1)</code>Â tensor.</p><pre id="404b8755-d79d-4e2a-898f-d78e7c882fd9" class="code code-wrap"><code>def process_image(dcm_path):
    &quot;&quot;&quot;Read Image from path and resize it to (224, 224)&quot;&quot;&quot;
    ds = dicom.dcmread(image_path)
    image = cv2.resize(ds.pixel_array, [224, 224]).reshape(224, 224, 1)
    return image</code></pre><p id="3e63ea35-4d7a-4847-bfa7-e4fedac3ea2a" class="">Next, we create a function that writes each example into the tfrecord file. The function takes the preprocessed image and target value as input and returns an instance ofÂ <code>tf.train.Example</code>Â . Each feature is processed using the helper functions defined above.</p><pre id="e4631cef-4aac-4489-b8ae-93722479e0d5" class="code code-wrap"><code>def create_example(image, target):
    &quot;&quot;&quot;Write example &quot;&quot;&quot;
    feature = {
        &quot;image&quot;: image_feature(image),
        &quot;target&quot;: int64_feature(target)
    }
    return tf.train.Example(features=tf.train.Features(feature=feature))</code></pre><p id="3c4e3968-f053-4aa5-b9b6-d504ff65d8fc" class="">Finally, using<code>tf.io.TFRecordWriter</code>Â , we write the dataset into tfrecord files.</p><pre id="9c9fd99e-9457-4ec1-9811-ac8d7b9c1ef5" class="code code-wrap"><code>for tfrec_num in range(num_tfrecords):
    samples = train[&#x27;image_id&#x27;][(tfrec_num * NUM_RECORDS) : ((tfrec_num + 1) * NUM_RECORDS)]
    tf_dir = tfrecords_dir + f&#x27;/tfrecord_{tfrec_num * NUM_RECORDS}-{(tfrec_num + 1) * NUM_RECORDS}.tfrec&#x27;
    with tf.io.TFRecordWriter(tf_dir) as writer:
        for sample in samples:
            image_path = train[train[&#x27;image_id&#x27;] == sample][&#x27;image_path&#x27;].iloc[0]
            image = process_image(image_path)
            target = train[train[&#x27;image_id&#x27;] == sample][&#x27;cancer&#x27;].iloc[0]
            record = create_example(image, target)
            writer.write(record.SerializeToString())</code></pre><p id="8be29e04-ad6b-4c8a-9119-ef9d10222fd9" class="">The code above writes the dataset into tfrecord files. The first two lines get the samples/data to be added to the tfrecord file and name the file asÂ <code>tfrecord_1000â2000.tfrec</code>Â (for samples 1000 to 2000).</p><p id="e54e61bb-0568-4265-a791-59f7c3f385e4" class="">Data is written to the tfrecord file one at a time. So using aÂ <code>for</code>Â loop, we loop over the samples and usingÂ <code>tf.io.TFRecordWriter</code>Â write each sample (example) to the tfrecord file. On the last line, notice the use ofÂ <code>write</code>Â andÂ <code>SerializeToString</code>Â methods. TheÂ <code>write</code>Â method writes the example andÂ <code>SerializeToString</code>Â converts the example to a binary string.</p><p id="a9581313-667e-4b2e-9104-c9b947627aab" class="">In theÂ <a href="https://medium.com/@sodipepaul/tfrecords-part-2-reading-and-training-models-with-tfrecords-b13f9cd2e575">second part</a>, we focus on reading data from a tfrecord file and training a Deep Neural Network with tfrecord files.</p><p id="53b507ee-8c84-45de-9023-1a370201fb2a" class="">You can read it here:Â <a href="https://medium.com/@sodipepaul/tfrecords-part-2-reading-and-training-models-with-tfrecords-b13f9cd2e575?source=user_profile---------0----------------------------">TFRecords (Part 2): Reading and training models with Tfrecords.</a></p><hr id="882727c4-3a85-46c2-80f9-ac85c929d598"/><p id="efa337bf-03e1-4b4c-b3fa-09d31d8fdfb5" class="">by sodipeð on Feburary 4, 2023</p></div></article></body></html>